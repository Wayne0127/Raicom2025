{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40a179b",
   "metadata": {},
   "source": [
    "# 睿抗 2025 智海人工智能算法应用赛\n",
    "**语音情绪识别**：推理测试代码  \n",
    "在这个笔记本上测试通过后，直接把关键部分复制到main.py即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99fdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2b4256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)  # Python 内置随机数\n",
    "    np.random.seed(seed)  # NumPy 随机数\n",
    "    torch.manual_seed(seed)  # CPU 上的随机数\n",
    "    torch.cuda.manual_seed(seed)  # GPU 上的随机数\n",
    "    torch.cuda.manual_seed_all(seed)  # 多 GPU 情况下的随机数\n",
    "    torch.backends.cudnn.deterministic = True  # 确保每次卷积结果一致\n",
    "    torch.backends.cudnn.benchmark = False     # 禁用自动优化\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3c8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8cc643",
   "metadata": {},
   "source": [
    "========================================  **测试提交函数示例**  =========================================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e540b743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  results/wav2vec2-base.zip\n",
      "   creating: wav2vec2-base/\n",
      "  inflating: wav2vec2-base/tokenizer_config.json  \n",
      "  inflating: wav2vec2-base/vocab.json  \n",
      "  inflating: wav2vec2-base/special_tokens_map.json  \n",
      "   creating: wav2vec2-base/.ipynb_checkpoints/\n",
      "  inflating: wav2vec2-base/README.md  \n",
      "  inflating: wav2vec2-base/config.json  \n",
      "  inflating: wav2vec2-base/preprocessor_config.json  \n",
      "  inflating: wav2vec2-base/pytorch_model.bin  \n"
     ]
    }
   ],
   "source": [
    "# ! unzip results/wav2vec2-base.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32913fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan 1000 362M Jun 28 12:50 results/wav2vec2_fold5.pt\n"
     ]
    }
   ],
   "source": [
    "# ! ls -lh results/wav2vec2_fold5.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d61a8c",
   "metadata": {},
   "source": [
    "### 推理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeccf3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/jovyan/.virtualenvs/basenv/lib/python3.9/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 3/3 [00:16<00:00,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 成功加载 3 个折模型\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch, torchaudio, torch.nn.functional as F, random\n",
    "import torch, torch.nn as nn\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor, Wav2Vec2Config\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------ 基本设置 ------------\n",
    "label_names = ['anger', 'fear', 'happy', 'neutral', 'sad']\n",
    "PRETRAINED = \"results/wav2vec2-base\"          # 可换成中文/多语权重\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(PRETRAINED)\n",
    "device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# ------------ 模型定义 ------------\n",
    "class AttentivePool(nn.Module):\n",
    "    \"\"\"自注意力池化：权重 = softmax(Linear(tanh(Linear)))\"\"\"\n",
    "    def __init__(self, hidden):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(hidden, hidden // 2)\n",
    "        self.linear2 = nn.Linear(hidden // 2, 1)\n",
    "\n",
    "    def forward(self, h):            # h: [B, T, C]\n",
    "        a = torch.tanh(self.linear1(h))\n",
    "        a = self.linear2(a).squeeze(-1)          # [B, T]\n",
    "        a = torch.softmax(a, dim=1).unsqueeze(-1)\n",
    "        return (h * a).sum(1)                    # [B, C]\n",
    "\n",
    "class HF_Wav2Vec2SER(nn.Module):\n",
    "    def __init__(self, num_cls=5, freeze_feat=True, pool=\"attn\"):\n",
    "        super().__init__()\n",
    "        config = Wav2Vec2Config.from_pretrained(PRETRAINED)  # 只取结构配置\n",
    "        self.encoder = Wav2Vec2Model(config)\n",
    "        if freeze_feat:\n",
    "            self.encoder.feature_extractor.requires_grad_(False)\n",
    "\n",
    "        hid = self.encoder.config.hidden_size           # 768\n",
    "\n",
    "        # ------- 池化层选择 -------\n",
    "        if pool == \"mean\":\n",
    "            self.pool = lambda h: h.mean(1)\n",
    "        elif pool == \"stat\":\n",
    "            self.pool = lambda h: torch.cat([h.mean(1), h.std(1)], dim=-1)\n",
    "            hid *= 2                                     # 因为拼接 mean+std\n",
    "        else:  # \"attn\"\n",
    "            self.pool = AttentivePool(hid)\n",
    "\n",
    "        # ------- 分类头 -------\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(hid),\n",
    "            nn.Linear(hid, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_cls)\n",
    "        )\n",
    "\n",
    "    def forward(self, wav, attn_mask):\n",
    "        h = self.encoder(wav, attention_mask=attn_mask,\n",
    "                         return_dict=True).last_hidden_state   # [B,T,C]\n",
    "        x = self.pool(h)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "# 加载模型\n",
    "# ------------ 加载 5 折模型 ------------\n",
    "models = []\n",
    "for i in tqdm(range(1, 4)):\n",
    "    m = HF_Wav2Vec2SER(len(label_names)).to(device)\n",
    "#     m = HF_HuBERT_SER(len(label_names)).to(device)\n",
    "    m.load_state_dict(torch.load(f\"results/wav2vec2_fold{i}.pt\", map_location=device), strict=True)\n",
    "    m.eval()\n",
    "    models.append(m)\n",
    "\n",
    "print(f\"✓ 成功加载 {len(models)} 个折模型\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(audio: torch.Tensor, sr: int) -> str:\n",
    "    target_sr, max_len = 16_000, 16_000 * 3\n",
    "\n",
    "    # 预处理：重采样 + 单声道 + 裁剪/填充\n",
    "    if sr != target_sr:\n",
    "        audio = torchaudio.functional.resample(audio, sr, target_sr)\n",
    "    if audio.dim() == 2 and audio.size(0) > 1:\n",
    "        audio = audio.mean(0)\n",
    "    audio = audio[:max_len] if audio.numel() > max_len else F.pad(audio, (0, max_len - audio.numel()))\n",
    "\n",
    "    # 特征提取\n",
    "    inputs = feature_extractor(\n",
    "        [audio.squeeze().numpy()],\n",
    "        sampling_rate=target_sr,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "    wav, attn = inputs.input_values.to(device), inputs.attention_mask.to(device)\n",
    "\n",
    "    # 集成推理：Softmax → 概率平均\n",
    "    prob_sum = torch.zeros((1, len(label_names)), device=device)\n",
    "    for m in models:\n",
    "        prob_sum += F.softmax(m(wav, attn), dim=-1)\n",
    "\n",
    "    pred_idx = prob_sum.argmax(1).item()\n",
    "    return label_names[pred_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37b00d",
   "metadata": {},
   "source": [
    "### 单条测试\n",
    "用于测试能不能调通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0515bca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_x, sr = torchaudio.load('./datasets/67fc7ccbb88b01da6626732d-momodel/train/sad/112.wav')\n",
    "predict(predict_x, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9e80e",
   "metadata": {},
   "source": [
    "### 批量测试\n",
    "用于预估时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e369c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 14:21:26.563955: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-27 14:21:26.565133: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-27 14:21:26.568989: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-27 14:21:26.578852: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-27 14:21:26.592752: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-27 14:21:26.596993: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-27 14:21:26.610813: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-27 14:21:27.736675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶  预测 10 条：35.675s  |  平均 3.568s/条\n",
      "▶  预测 20 条：68.895s  |  平均 3.445s/条\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "# ----------------- 基准测试 -----------------\n",
    "def benchmark(n=10, root=\"./datasets/67fc7ccbb88b01da6626732d-momodel/train\"):\n",
    "    files = random.sample(glob.glob(f\"{root}/**/*.wav\", recursive=True), n)\n",
    "\n",
    "    # warm-up（第一次跑会触发编译与缓存）\n",
    "    wav, sr = torchaudio.load(files[0]); _ = predict(wav, sr)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for f in files:\n",
    "        wav, sr = torchaudio.load(f)\n",
    "        _ = predict(wav, sr)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    total = t1 - t0\n",
    "    print(f\"▶  预测 {n:>2} 条：{total:.3f}s  |  平均 {total/n:.3f}s/条\")\n",
    "\n",
    "benchmark(10)\n",
    "benchmark(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f776ebd5",
   "metadata": {},
   "source": [
    "### 最后测试main.py 文件，这里用main_test.py 暂时替代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87bf4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len models 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main_test import predict\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "# import torchaudio.functional as audiof\n",
    "# import numpy as np\n",
    "\n",
    "predict_x, sr = torchaudio.load('./datasets/67fc7ccbb88b01da6626732d-momodel/train/sad/2.wav')\n",
    "predict(predict_x, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
